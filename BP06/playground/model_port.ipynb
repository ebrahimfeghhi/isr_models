{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from itertools import permutations \n",
    "import sys\n",
    "base = '/home3/ebrahim/isr/'\n",
    "sys.path.append(base)\n",
    "from datasets import OneHotLetters, OneHotLetters_test\n",
    "from RNNcell import RNN_one_layer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import block_reduce\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from itertools import permutations, islice\n",
    "import wandb\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import FALSE\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "\n",
    "class RNNcell(nn.Module):\n",
    "\n",
    "    \"\"\" Vanilla RNN with:\n",
    "            - Feedback from output\n",
    "            - Sigmoid nonlinearity over hidden activations \n",
    "            - Softmax activation over output \n",
    "            - Initialization follows Botvinick and Plaut, 2006 \n",
    "            - Incorporated plastic connections based on Miconi, 2018\n",
    "            - Contextual variable binding \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_size, hidden_size, output_size, noise_std, nonlin,\n",
    "                bias, feedback_bool, alpha_s, plastic, context, context_size, rule, h2h_weights):\n",
    "\n",
    "        \"\"\" Init model.\n",
    "        @param data_size (int): Input size\n",
    "        @param hidden_size (int): the size of hidden states\n",
    "        @param output_size (int): number of classes\n",
    "        @param noise_std (float): std. dev. for gaussian noise\n",
    "        @param nonlin (str): Nonlinearity for hidden activations: sigmoid, relu, tanh, or linear.\n",
    "        @param h2h_bias (bool): if true, bias units are used for hidden units\n",
    "        @param feedback_bool (bool): if true, feedback connections are implemented\n",
    "        @param feedback_size (int): size of feedback units, if None defaults to output_size\n",
    "        @param plastic (bool): if true, implement hebbian connections \n",
    "        @param context (bool): if true, then hebbian weights are formed between RNN hidden activity and context\n",
    "        \"\"\"\n",
    "        super(RNNcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.nonlin = nonlin\n",
    "        self.noise_std = noise_std\n",
    "        self.feedback_bool = feedback_bool\n",
    "        self.alpha_s = alpha_s\n",
    "        self.plastic = plastic\n",
    "        self.context = context\n",
    "        self.context_size = context_size\n",
    "        self.rule = rule\n",
    "        self.h2h_weights = h2h_weights\n",
    "\n",
    "        # recurrent to recurrent connections \n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "        nn.init.uniform_(self.h2h.weight, -0.5, 0.5)\n",
    "        \n",
    "        # input to recurrent unit connections \n",
    "        self.i2h = nn.Linear(data_size, hidden_size, bias=False)\n",
    "        nn.init.uniform_(self.i2h.weight, -1.0, 1.0)\n",
    "\n",
    "        # output to recurrent connections \n",
    "        # default to output size if no feedback size is specified \n",
    "        feedback_size = output_size\n",
    "\n",
    "        self.o2h = nn.Linear(feedback_size, hidden_size, bias=False)\n",
    "        nn.init.uniform_(self.o2h.weight, -1.0, 1.0)\n",
    "\n",
    "        if self.plastic:\n",
    "            # plasticity coefficients\n",
    "            self.alpha =  torch.nn.Parameter(torch.rand((hidden_size, hidden_size))*2 - 1)\n",
    "            self.alpha.requires_grad = True\n",
    "\n",
    "            # learning rate for plasticity, we'll allow the network to learn this \n",
    "            self.eta = torch.nn.Parameter(torch.Tensor([0.01]))\n",
    "            self.eta.requires_grad = True\n",
    "\n",
    "        if self.context: \n",
    "\n",
    "            self.alpha_c =  torch.nn.Parameter(torch.rand((context_size, hidden_size))*2 - 1)\n",
    "            self.alpha_c.requires_grad = True\n",
    "\n",
    "            self.eta_c = torch.nn.Parameter(torch.Tensor([0.01]))\n",
    "            self.eta_c.requires_grad = True\n",
    "  \n",
    "        if nonlin == 'sigmoid':\n",
    "            self.F = nn.Sigmoid()\n",
    "        if nonlin == 'relu':\n",
    "            self.F = nn.ReLU()\n",
    "        if nonlin == 'tanh':\n",
    "            self.F = nn.Tanh()\n",
    "        if nonlin == 'linear':\n",
    "            self.F = nn.Identity()\n",
    "        if nonlin == 'relu6':\n",
    "            self.F == nn.ReLU6()\n",
    "\n",
    "    def forward(self, data, h_prev, feedback, hebb, context_hebb, i_prev, context_signal, device):\n",
    "        \"\"\"\n",
    "        @param data: input at time t\n",
    "        @param r_prev: firing rates at time t-1\n",
    "        @param x_prev: membrane potential values at time t-1\n",
    "        @param feedback: feedback from previous timestep\n",
    "        @param hebb: hebbian weights\n",
    "        @param context_hebb: hebbian weights from context to hidden state\n",
    "        @param i_prev: if using continuous time RNN \n",
    "        \"\"\"\n",
    "        \n",
    "        noise = self.noise_std*torch.randn(h_prev.shape).to(device)\n",
    "\n",
    "        # h2h hebbian connections\n",
    "        if self.plastic:\n",
    "            hebb_activity = h_prev@torch.mul(self.alpha, hebb)[0]\n",
    "        else:\n",
    "            hebb_activity = torch.zeros((h_prev.shape[0], self.hidden_size)).to(device)\n",
    "\n",
    "        # context2h hebbian connections \n",
    "        if self.context:\n",
    "            context_activity = context_signal@torch.mul(self.alpha_c, context_hebb)[0]\n",
    "        else:\n",
    "            context_activity = torch.zeros((h_prev.shape[0], self.hidden_size)).to(device)\n",
    "\n",
    "        # Only allow hebbian recurrent weights if false\n",
    "        if self.h2h_weights:\n",
    "            h_contribution = self.h2h(h_prev)\n",
    "        else:\n",
    "            h_contribution = h_prev\n",
    "\n",
    "        i = (1-self.alpha_s)*i_prev + self.alpha_s*(hebb_activity + self.i2h(data) + h_contribution \n",
    "        + self.o2h(feedback) + context_activity + noise)\n",
    "        h = self.F(i)\n",
    "\n",
    "        if self.plastic:\n",
    "            if self.rule == 'oja':\n",
    "                hebb = hebb + self.eta_c * torch.mul((h_prev[0].unsqueeze(1) - \n",
    "                torch.mul(hebb , h[0].unsqueeze(0))) , h[0].unsqueeze(0))\n",
    "\n",
    "            if self.rule == 'decay': \n",
    "                hebb = (1-self.eta)*hebb + self.eta*torch.bmm(h_prev.unsqueeze(2), h.unsqueeze(1))[0]\n",
    "\n",
    "        if self.context:\n",
    "            if self.rule == 'oja':\n",
    "                context_hebb = context_hebb + self.eta_c * torch.mul((context_signal[0].unsqueeze(1) - \n",
    "                torch.mul(context_hebb , h[0].unsqueeze(0))) , h[0].unsqueeze(0))\n",
    "\n",
    "            if self.rule == 'decay':\n",
    "                context_hebb = (1-self.eta_c)*context_hebb + self.eta_c*torch.bmm(context_signal.unsqueeze(2), \n",
    "                h.unsqueeze(1))[0]\n",
    "\n",
    "        return h, hebb, i, context_hebb\n",
    "\n",
    "class RNN_one_layer(nn.Module):\n",
    "\n",
    "    \"\"\" Single layer RNN \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, feedback_bool, bias, \n",
    "        nonlin='sigmoid', noise_std=0.0, plastic=False, alpha_s=1.0, context=False, context_size=0, rule='decay', \n",
    "        h2h_weights=True):\n",
    "\n",
    "        \"\"\" Init model.\n",
    "        @param data_size: Input size\n",
    "        @param hidden_size: the size of hidden states\n",
    "        @param output_size: number of classes\n",
    "        \"\"\"\n",
    "        super(RNN_one_layer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.context_size = context_size\n",
    "            \n",
    "        self.RNN = RNNcell(input_size, hidden_size, output_size, noise_std, nonlin, \n",
    "        bias=bias, feedback_bool=feedback_bool, plastic=plastic, alpha_s=alpha_s, \n",
    "        context=context, context_size=context_size, rule=rule, h2h_weights=h2h_weights)\n",
    "\n",
    "        self.h2o = nn.Linear(hidden_size, output_size, bias=bias)\n",
    "        nn.init.uniform_(self.h2o.weight, -1.0, 1.0)\n",
    "\n",
    "    def forward(self, data, h_prev, o_prev, hebb_prev, ch_prev, i_prev, device, context_signal=None):\n",
    "        \"\"\"\n",
    "        @param data: input at time t\n",
    "        @param h_prev : firing rates at time t-1 \n",
    "        @param o_prev: output at time t-1\n",
    "        \"\"\"\n",
    "        h, hebb, i, context_hebb = self.RNN(data, h_prev, o_prev, hebb_prev, ch_prev, i_prev, context_signal, device)\n",
    "\n",
    "        output = self.h2o(h)\n",
    "\n",
    "        return output, h, hebb, context_hebb, i\n",
    "\n",
    "    def init_states(self, batch_size, device, h0_init_val):\n",
    "\n",
    "        output = torch.zeros(batch_size, self.output_size).to(device)\n",
    "        h0 = torch.full((batch_size, self.hidden_size), float(h0_init_val)).to(device)\n",
    "        hebb0 = torch.zeros(batch_size, self.hidden_size, self.hidden_size).to(device)\n",
    "        context_hebb0 = torch.zeros(batch_size, self.context_size, self.hidden_size).to(device)\n",
    "        i0 = torch.full((batch_size, self.hidden_size), float(0.0)).to(device)\n",
    "       \n",
    "        return output, h0, hebb0, context_hebb0, i0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize untrained model\n",
    "batch_size = 1\n",
    "model = RNN_one_layer(28, 200, 28, noise_std=0,\n",
    "                        feedback_bool=True, bias=False, plastic=False, context=False, context_size=0)\n",
    "model = model.to(device)\n",
    "\n",
    "# create dataloader\n",
    "rtt = DataLoader(OneHotLetters(9, 100, '/home3/ebrahim/isr/test_set/test_lists_set.pkl', 28, batch_size=batch_size, num_letters=26, \n",
    "delay_start=3, delay_middle=1), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init initial states\n",
    "y0, h0, hebb0, ch0, i0 = model.init_states(batch_size, device, \n",
    "            0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model can leave the port!\n"
     ]
    }
   ],
   "source": [
    "# Let's test if the model works \n",
    "for batch_idx, (X,y) in enumerate(rtt):\n",
    "\n",
    "    h_current_list = []\n",
    "\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # run RNN and compute loss\n",
    "    for timestep in range(X.shape[1]):\n",
    "\n",
    "        # initial feedback \n",
    "        if timestep == 0:\n",
    "            y_hat, h, hebb, c_hebb, i = model(X[:, timestep, :], h0, y0, hebb0, ch0, i0, device)\n",
    "        else:\n",
    "            y_hat, h, hebb, c_hebb, i = model(X[:, timestep, :], h, y[:, timestep-1, :], hebb, c_hebb, i, device)\n",
    "            \n",
    "        h_current_list.append(h.detach())\n",
    "\n",
    "    break\n",
    "\n",
    "print(\"Model can leave the port!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_current_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20, 100])\n"
     ]
    }
   ],
   "source": [
    "c_hebb = torch.zeros((20,100))\n",
    "h = torch.zeros((2,100)) \n",
    "cs = torch.zeros((2,20))\n",
    "\n",
    "\n",
    "h_chebb = cs.unsqueeze(2) - torch.mul(h.unsqueeze(1), c_hebb)\n",
    "print(h_chebb.shape)\n",
    "#c_hebb_new = c_hebb + (0.1 * torch.mul(h.unsqueeze(2),cs.unsqueeze(1)) - 0.1 * torch.mul(h.unsqueeze(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "tensor([[[0.5000, 0.7500, 0.9500, 0.9500, 0.9900],\n",
      "         [0.5000, 0.7500, 0.9500, 0.9500, 0.9900],\n",
      "         [0.5000, 0.7500, 0.9500, 0.9500, 0.9900]],\n",
      "\n",
      "        [[0.0000, 0.7500, 0.9500, 0.9500, 0.9900],\n",
      "         [0.0000, 0.7500, 0.9500, 0.9500, 0.9900],\n",
      "         [0.0000, 0.7500, 0.9500, 0.9500, 0.9900]]])\n"
     ]
    }
   ],
   "source": [
    "h = torch.Tensor([[.5, .25, .05, .05, .01], [1, .25, .05, .05, .01]])\n",
    "chebb = torch.ones((3,5))\n",
    "cs = torch.ones((2,3))\n",
    "g = torch.mul((cs[0].unsqueeze(1) - torch.mul(chebb , h[0].unsqueeze(0))) , h[0].unsqueeze(0))\n",
    "print(g.shape)\n",
    "print((cs.unsqueeze(2) - torch.mul(h.unsqueeze(1), chebb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
