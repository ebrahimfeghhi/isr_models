{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StimSampler():\n",
    "    '''\n",
    "    a sampler of sequences\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_param,\n",
    "            n_branch,\n",
    "            pad_len=0,\n",
    "            max_pad_len=None,\n",
    "            def_path=None,\n",
    "            def_prob=None,\n",
    "            def_tps=None,\n",
    "            key_rep_type='time',\n",
    "            rm_kv=False,\n",
    "            context_onehot=True,\n",
    "            context_dim=1,\n",
    "            context_drift=False,\n",
    "            n_rm_fixed=False,\n",
    "            sampling_mode='enumerative',\n",
    "            repeat_query=False,\n",
    "    ):\n",
    "        self.n_param = n_param\n",
    "        self.n_branch = n_branch\n",
    "        self.pad_len = pad_len\n",
    "        if max_pad_len is None:\n",
    "            self.max_pad_len = np.max([n_param // 3 - 1, 0])\n",
    "        #\n",
    "        self.def_path = def_path\n",
    "        self.def_prob = def_prob\n",
    "        self.def_tps = def_tps\n",
    "        #\n",
    "        self.context_onehot = context_onehot\n",
    "        self.context_dim = context_dim\n",
    "        self.context_drift = context_drift\n",
    "        #\n",
    "        self.key_rep_type = key_rep_type\n",
    "        self.sampling_mode = sampling_mode\n",
    "        #\n",
    "        self.rm_kv = rm_kv\n",
    "        self.n_rm_fixed = n_rm_fixed\n",
    "        #\n",
    "        self.repeat_query=repeat_query\n",
    "        #\n",
    "        self.reset_schema()\n",
    "\n",
    "    def reset_schema(self):\n",
    "        \"\"\"re-initialize the schema\n",
    "        \"\"\"\n",
    "        self.schema = Schema(\n",
    "            n_param=self.n_param,\n",
    "            n_branch=self.n_branch,\n",
    "            def_path=self.def_path,\n",
    "            def_prob=self.def_prob,\n",
    "            def_tps=self.def_tps,\n",
    "            context_onehot=self.context_onehot,\n",
    "            context_dim=self.context_dim,\n",
    "            context_drift=self.context_drift,\n",
    "            key_rep_type=self.key_rep_type,\n",
    "            sampling_mode=self.sampling_mode,\n",
    "        )\n",
    "        self.k_dim = self.schema.k_dim\n",
    "        self.v_dim = self.schema.v_dim\n",
    "        self.c_dim = self.schema.c_dim\n",
    "\n",
    "    def _sample(self):\n",
    "        \"\"\"sample an event sequence, one-hot vector representation\n",
    "        Returns\n",
    "        -------\n",
    "        2d np array, 2d np array; T x (T x B), T x B\n",
    "            sequence of keys / parameter values over time\n",
    "        \"\"\"\n",
    "        # sample keys and parameter values, integer representation\n",
    "        keys, vals = self.schema.sample()\n",
    "        # translate to vector representation\n",
    "        keys_vec = np.vstack([self.schema.key_rep[k_t, :] for k_t in keys])\n",
    "        vals_vec = np.vstack([self.schema.val_rep[v_t, :] for v_t in vals])\n",
    "        # ctxs_vec = np.vstack([self.schema.ctx_rep[v_t, :] for v_t in vals])\n",
    "        ctxs_vec = np.vstack([self.schema.ctx_rep])\n",
    "        misc = [keys, vals]\n",
    "        return keys_vec, vals_vec, ctxs_vec, misc\n",
    "\n",
    "    def sample(\n",
    "            self,\n",
    "            n_parts=2, p_rm_ob_enc=0, p_rm_ob_rcl=0,\n",
    "            permute_observations=True, permute_queries=False,\n",
    "    ):\n",
    "        \"\"\"sample a multi-part \"movie\", with repetition structure\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_parts : int\n",
    "            the number of parts in this event sequence\n",
    "        format: string\n",
    "            the output data format\n",
    "            - 'okv-qkv': human-readble form\n",
    "            - 'xy': nn-readable form\n",
    "        Returns\n",
    "        -------\n",
    "        3d np array, 3d np array; nP x T x (T x B), nP x T x B\n",
    "            sequence of keys / parameter values over time\n",
    "            different parts are consistent\n",
    "        \"\"\"\n",
    "        # sample the state-param associtations\n",
    "        keys_vec_, vals_vec_, ctxs_vec_, misc = self._sample()\n",
    "        # sample for the observation phase\n",
    "        o_keys_vec, o_vals_vec = self._sample_permutations_sup(\n",
    "            keys_vec_, vals_vec_, n_parts, permute_observations)\n",
    "        q_keys_vec, q_vals_vec = self._sample_permutations_sup(\n",
    "            keys_vec_, vals_vec_, n_parts, permute_queries)\n",
    "        # corrupt input during encoding\n",
    "        o_keys_vec, o_vals_vec = self._corrupt_observations(\n",
    "            o_keys_vec, o_vals_vec, p_rm_ob_enc, p_rm_ob_rcl)\n",
    "        # context are assumed to repeat across the two phases\n",
    "        o_ctxs_vec = q_ctxs_vec = ctxs_vec_\n",
    "        # whether to repeat query\n",
    "        if self.repeat_query:\n",
    "            q_keys_vec = [get_botvinick_query(self.n_param) for _ in range(n_parts)]\n",
    "        # pack sample\n",
    "        o_sample_ = [o_keys_vec, o_vals_vec, o_ctxs_vec]\n",
    "        q_sample_ = [q_keys_vec, q_vals_vec, q_ctxs_vec]\n",
    "        # padding, if there is a delay\n",
    "        [o_sample_, q_sample_] = self._delay_pred_demand(o_sample_, q_sample_)\n",
    "        # pack sample\n",
    "        sample_ = [o_sample_, q_sample_]\n",
    "        return sample_, misc\n",
    "\n",
    "    def _sample_permutations_sup(\n",
    "        self, keys_vec_raw, vals_vec_raw, n_parts, permute\n",
    "    ):\n",
    "        if permute:\n",
    "            s_keys_vec, s_vals_vec = self._sample_permutations(\n",
    "                keys_vec_raw, vals_vec_raw, n_parts)\n",
    "        else:\n",
    "            s_keys_vec = np.stack([keys_vec_raw for _ in range(n_parts)])\n",
    "            s_vals_vec = np.stack([vals_vec_raw for _ in range(n_parts)])\n",
    "        return s_keys_vec, s_vals_vec\n",
    "\n",
    "    def _sample_permutations(self, keys_vec_raw, vals_vec_raw, n_perms):\n",
    "        \"\"\"given some raw key-val pairs, generate temporal permutation sets\n",
    "        \"\"\"\n",
    "        T = self.n_param\n",
    "        keys_vec = np.zeros((n_perms, T, self.k_dim))\n",
    "        vals_vec = np.zeros((n_perms, T, self.v_dim))\n",
    "        # ctxs_vec = np.zeros((n_perms, T, self.c_dim))\n",
    "        for ip in range(n_perms):\n",
    "            # unique permutation for each movie part\n",
    "            perm_op = np.random.permutation(T)\n",
    "            keys_vec[ip] = keys_vec_raw[perm_op, :]\n",
    "            vals_vec[ip] = vals_vec_raw[perm_op, :]\n",
    "            # ctxs_vec[ip] = ctxs_vec_raw[perm_op, :]\n",
    "        return keys_vec, vals_vec\n",
    "\n",
    "    def _corrupt_observations(\n",
    "        self,\n",
    "        o_keys_vec, o_vals_vec,\n",
    "        p_rm_ob_enc, p_rm_ob_rcl,\n",
    "    ):\n",
    "        \"\"\"corrupt observations\n",
    "        currently I only implemented zero-ing out random rows, but this function\n",
    "        can be more general than this\n",
    "        Parameters\n",
    "        ----------\n",
    "        o_keys_vec : 3d np array, nP x T x (T x B)\n",
    "            keys, or states\n",
    "        o_vals_vec : 3d np array, nP x T x B\n",
    "            values, or actions\n",
    "        p_rm_ob_enc : float\n",
    "            p(zero-ing out observation at time t) during encoding\n",
    "        p_rm_ob_rcl : float\n",
    "            p(zero-ing out observation at time t) during recall\n",
    "        Returns\n",
    "        -------\n",
    "        3d np array, 3d np array; nP x T x (T x B), nP x T x B\n",
    "            keys,values after corruption\n",
    "        \"\"\"\n",
    "        # the 1st part is the encoding phase\n",
    "        # all remaining parts are query phase\n",
    "        n_parts = len(o_keys_vec)\n",
    "        # get a list of p_rm, only the 1st phase is the encoding phase\n",
    "        # the rest of phases are considered as recall phases\n",
    "        p_rms = [p_rm_ob_enc] * (n_parts - 1) + [p_rm_ob_rcl]\n",
    "        # zero out random rows (time steps)\n",
    "        for ip in range(n_parts):\n",
    "            # zero out both key and values\n",
    "            if self.rm_kv:\n",
    "                [o_keys_vec[ip], o_vals_vec[ip]] = _zero_out_random_rows(\n",
    "                    [o_keys_vec[ip], o_vals_vec[ip]], p_rms[ip],\n",
    "                    n_rm_fixed=self.n_rm_fixed\n",
    "                )\n",
    "            # zero out values only\n",
    "            # in this case the agent know which state is unknown\n",
    "            else:\n",
    "                [o_vals_vec[ip]] = _zero_out_random_rows(\n",
    "                    [o_vals_vec[ip]], p_rms[ip],\n",
    "                    n_rm_fixed=self.n_rm_fixed\n",
    "                )\n",
    "        return o_keys_vec, o_vals_vec\n",
    "\n",
    "    def _delay_pred_demand(self, o_sample_, q_sample_):\n",
    "        \"\"\"apply delay to the queries, and zero pad the end of observations\n",
    "        Parameters\n",
    "        ----------\n",
    "        o_sample_ : list\n",
    "            observations\n",
    "        q_sample_ : list\n",
    "            queries\n",
    "        Returns\n",
    "        -------\n",
    "        list, list\n",
    "            padded observations and queries\n",
    "        \"\"\"\n",
    "        if self.pad_len == 0 or self.max_pad_len == 0:\n",
    "            return o_sample_, q_sample_\n",
    "        # uniformly sample a padding length\n",
    "        if self.pad_len == 'random':\n",
    "            # high is exclusive so need to add 1\n",
    "            pad_len = np.random.randint(low=0, high=self.max_pad_len + 1)\n",
    "        # fixed padding length\n",
    "        elif self.pad_len > 0:\n",
    "            pad_len = self.pad_len\n",
    "        else:\n",
    "            raise ValueError(f'Invalid delay length: {self.pad_len}')\n",
    "\n",
    "        # padd the data\n",
    "        o_sample_ = _zero_pad_kvc(o_sample_, pad_len, side='bot')\n",
    "        q_sample_ = _zero_pad_kvc(q_sample_, pad_len, side='top')\n",
    "        return o_sample_, q_sample_\n",
    "\n",
    "\n",
    "def _zero_out_random_rows(matrices, p_rm, n_rm_fixed=True):\n",
    "    \"\"\"zero out the same set of (randomly selected) rows for all input matrices\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrices : list\n",
    "        a list of 2d arrays\n",
    "    p_rm : float\n",
    "        probability for set a row of zero\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of 2d arrays\n",
    "    \"\"\"\n",
    "    assert 0 <= p_rm <= 1\n",
    "    n_rows, _ = np.shape(matrices[0])\n",
    "    for matrix in matrices:\n",
    "        assert np.shape(matrix)[0] == n_rows\n",
    "    # select # row(s) to zero out\n",
    "    if n_rm_fixed:\n",
    "        n_rows_to0 = np.ceil(p_rm * n_rows)\n",
    "    else:\n",
    "        # in this case, p_rm == E[rows_to_remove]\n",
    "        max_rows_to_remove = p_rm * n_rows\n",
    "        n_rows_to0 = np.round(np.random.uniform(high=max_rows_to_remove))\n",
    "    # select some rows to zero out\n",
    "    rows_to0 = np.random.choice(\n",
    "        range(n_rows), size=int(n_rows_to0), replace=False\n",
    "    )\n",
    "    # zero out the same rows for all input matrices\n",
    "    for i in range(len(matrices)):\n",
    "        matrices[i][rows_to0, :] = 0\n",
    "    return matrices\n",
    "\n",
    "\n",
    "def _zero_pad_kvc(kvc: list, pad_len: int, side: str):\n",
    "    \"\"\"delay the prediction demand by shifting the query value to later time\n",
    "    points\n",
    "    Parameters\n",
    "    ----------\n",
    "    kvc : list\n",
    "        Description of parameter `kvc`.\n",
    "    pad_len : int\n",
    "        Description of parameter `pad_len`.\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "    \"\"\"\n",
    "    # unpack data\n",
    "    keys_vec, vals_vec, ctxs_vec = kvc\n",
    "    n_parts, n_params, k_dim = np.shape(keys_vec)\n",
    "    _, _, v_dim = np.shape(vals_vec)\n",
    "    _, c_dim = np.shape(ctxs_vec)\n",
    "    # pad to delay prediction time\n",
    "    keys_vec = [_vpad(k_mat, pad_len, side=side) for k_mat in keys_vec]\n",
    "    vals_vec = [_vpad(v_mat, pad_len, side=side) for v_mat in vals_vec]\n",
    "    # TODO here i assumed context is always in sync with the queries\n",
    "    # but probably want to generate additional context for the padding period\n",
    "    ctxs_vec = _vpad(ctxs_vec, pad_len, side='top')\n",
    "    # pack the data\n",
    "    kvc_ = [keys_vec, vals_vec, ctxs_vec]\n",
    "    return kvc_\n",
    "\n",
    "\n",
    "def _vpad(matrix, pad_len: int, side: str):\n",
    "    '''vertically pad zeros from the top or bot'''\n",
    "    #\n",
    "    n_rows, n_cols = np.shape(matrix)\n",
    "    zero_padding = np.zeros((pad_len, n_cols))\n",
    "    if side == 'top':\n",
    "        padded_matrix = np.vstack([zero_padding, matrix])\n",
    "    elif side == 'bot':\n",
    "        padded_matrix = np.vstack([matrix, zero_padding])\n",
    "    else:\n",
    "        raise ValueError('Unrecognizable padding side')\n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "from utils.utils import to_pth\n",
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "\n",
    "\n",
    "class SequenceLearning():\n",
    "    \"\"\"a key-value assoc learning task with explicit query keys input,\n",
    "    - ... where query keys are not explicitly presented\n",
    "    - but queries are always ordered by \"time\", so the model knows which\n",
    "    element is being queried\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_param,\n",
    "            n_branch,\n",
    "            pad_len=0,\n",
    "            max_pad_len=None,\n",
    "            n_parts=2,\n",
    "            def_path=None,\n",
    "            def_prob=None,\n",
    "            def_tps=None,\n",
    "            p_rm_ob_enc=0,\n",
    "            p_rm_ob_rcl=0,\n",
    "            n_rm_fixed=False,\n",
    "            similarity_max=None,\n",
    "            similarity_min=None,\n",
    "            similarity_cap_lag=2,\n",
    "            permute_queries=False,\n",
    "            permute_observations=True,\n",
    "            key_rep_type='time',\n",
    "            sampling_mode='enumerative',\n",
    "            repeat_query=False,\n",
    "    ):\n",
    "        # build a sampler\n",
    "        self.stim_sampler = StimSampler(\n",
    "            n_param=n_param,\n",
    "            n_branch=n_branch,\n",
    "            pad_len=pad_len,\n",
    "            max_pad_len=max_pad_len,\n",
    "            def_path=def_path,\n",
    "            def_prob=def_prob,\n",
    "            def_tps=def_tps,\n",
    "            key_rep_type=key_rep_type,\n",
    "            n_rm_fixed=n_rm_fixed,\n",
    "            sampling_mode=sampling_mode,\n",
    "            repeat_query=repeat_query,\n",
    "        )\n",
    "        # graph param\n",
    "        self.n_param = n_param\n",
    "        self.n_branch = n_branch\n",
    "        self.n_parts = n_parts\n",
    "        self.pad_len = pad_len\n",
    "        #\n",
    "        self.max_pad_len = self.stim_sampler.max_pad_len\n",
    "        self.T_part_max = self.n_param + self.max_pad_len\n",
    "        self.T_total_max = self.T_part_max * self.n_parts\n",
    "        # \"noise\" in the obseravtion\n",
    "        self.p_rm_ob_enc = p_rm_ob_enc\n",
    "        self.p_rm_ob_rcl = p_rm_ob_rcl\n",
    "        self.n_rm_fixed = n_rm_fixed\n",
    "        # whether to permute queries\n",
    "        self.permute_queries = permute_queries\n",
    "        self.permute_observations = permute_observations\n",
    "        # task dimension\n",
    "        self.k_dim = self.stim_sampler.k_dim\n",
    "        self.v_dim = self.stim_sampler.v_dim\n",
    "        self.x_dim = self.k_dim * 2 + self.v_dim\n",
    "        self.y_dim = self.v_dim\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
