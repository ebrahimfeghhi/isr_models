{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTrialSEM():\n",
    "\n",
    "    '''\n",
    "    This class implements to multi-trial version of SEM, as described by Henson (1998).\n",
    "    Limited to grouping at a single level, will extend later if needed.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, param_dict):\n",
    "\n",
    "        '''\n",
    "         param_dict contains the following keys: \n",
    "\n",
    "        :param float s0: initial strength of start marker \n",
    "        :param float e0: initial strength of end marker\n",
    "        :param float S: change rate for start marker\n",
    "        :param float E: change rate for end marker\n",
    "        :param float E_c: contextual drift\n",
    "        :param float G_c: std. dev. of zero mean gaussian dist. for recall selection process \n",
    "        :param float G_p: std. dev. of zero mean gaussian dist. for phonological selection process \n",
    "        :param float A_p: phonological representation\n",
    "        :param flaot P_s: phonological similarity for confusable items\n",
    "        :param float P_d: phonological similarity for non-confusable items \n",
    "        :param float R_s: decay rate for response suppression \n",
    "        :param float R_p: decay rate for phonological activations\n",
    "        :param float T_o: threshold for response \n",
    "        :param int C_p: number of episodes between presentation of each item \n",
    "        :param int C_d: number of episodes between during the retention interval \n",
    "        :param int C_r: number of episodes between recall of each item \n",
    "        :param int C_i: number of episodes between trials\n",
    "        :param int C_a: additional contextual change between trials \n",
    "        :param int vocab_size: number of items/items \n",
    "        '''\n",
    "        self.s0 = param_dict['s0'] \n",
    "        self.e0 = param_dict['e0'] \n",
    "        self.S = param_dict['S'] \n",
    "        self.E = param_dict['E'] \n",
    "        self.E_c = param_dict['E_c'] \n",
    "        self.G_c = param_dict['G_c'] \n",
    "        self.G_p = param_dict['G_p']\n",
    "        self.A_p = param_dict['A_p']\n",
    "        self.P_s = param_dict['P_s']\n",
    "        self.P_d = param_dict['P_d']\n",
    "        self.R_s = param_dict['R_s']\n",
    "        self.R_p = param_dict['R_p']\n",
    "        self.T_o = param_dict['T_o']\n",
    "        self.C_p = param_dict['C_p']\n",
    "        self.C_d = param_dict['C_d']\n",
    "        self.C_r = param_dict['C_r']\n",
    "        self.C_i = param_dict['C_i']\n",
    "        self.C_a = param_dict['C_a']\n",
    "        self.vocab_size = param_dict['vocab_size'] # number of types in LTM \n",
    "        self.max_tokens = param_dict['max_tokens'] # max number of tokens that can be stored, somewhat arbitrary\n",
    "        self.present_context = 1\n",
    "        self.suppression = 1 \n",
    "        self.list_position_tokens = [] # stores start and end markers for list position\n",
    "        self.group_position_tokens = [] # stores start and end markers for group position \n",
    "        self.stored_tokens = [] # stores only tokens that are in SEM, this is used by SEM\n",
    "        self.context_tokens = [] # stores context markers \n",
    "        self.response_suppression = np.zeros(self.vocab_size)\n",
    "        self.phonological_activations = np.zeros(self.vocab_size)\n",
    "        self.num_correct = 0 # number of lists recalled correctly\n",
    "        self.num_omissions = 0 \n",
    "        self.num_intrusions = 0\n",
    "\n",
    "        # store all tokens to quantify errors\n",
    "        self.all_stored_tokens = [] \n",
    "        self.all_context_tokens = [] \n",
    "        self.all_list_position_tokens = []\n",
    "        self.all_group_position_tokens = []\n",
    "\n",
    "    def start_end_markers(self, list_length, group_size, list_pos, group_pos):\n",
    "\n",
    "        '''\n",
    "        Generates start and end markers indicating list position and group position. \n",
    "\n",
    "        :param int list_length: length of entire list\n",
    "        :param int group_size: size of a group \n",
    "        :param int list_pos: position of item on list\n",
    "        :param int group_num: group number that item belongs in \n",
    "        '''\n",
    "\n",
    "        list_pos_marker = np.asarray([np.round(self.s0*self.S**(list_pos-1.0),2), np.round(self.e0*self.E**(list_length-list_pos), 2)])\n",
    "        group_pos_marker = np.asarray([np.round(self.s0*self.S**(group_pos-1.0),2), np.round(self.e0*self.E**(group_size-group_pos), 2)])\n",
    "\n",
    "        return list_pos_marker, group_pos_marker\n",
    "\n",
    "    def overlap_function(self, p_j, p_t):\n",
    "\n",
    "        '''\n",
    "        Computes the overlap between between two vectors \n",
    "\n",
    "        :param list p_j: 2x1  positional for response j, or 1x1  contextual marker \n",
    "        :param list p_t: 2x1 positional cue for item presented \n",
    "        at time t during the presentation phase\n",
    "        '''\n",
    "\n",
    "        exp_term = np.exp(-np.sum((p_t - p_j)**2)**.5)\n",
    "\n",
    "        return np.round(np.dot(p_j, p_t)**.5 * exp_term, 5)\n",
    "\n",
    "    def positional_cues(self, n, plot=False):\n",
    "\n",
    "        '''\n",
    "        :param int n: length of list \n",
    "        '''\n",
    "\n",
    "        pos_matrix = np.zeros((n, ))\n",
    "\n",
    "        s_arr = [] # start marker array\n",
    "        e_arr = [] # end marker array\n",
    "        c_arr = np.ones(n) # context markers \n",
    "\n",
    "        for i in range(n):\n",
    "            s, e = self.start_end_markers(i+1)\n",
    "            s_arr.append(s)\n",
    "            e_arr.append(e)\n",
    "            c_arr[:i+1] = c_arr[:i+1] * self.E_c\n",
    "            \n",
    "        if plot: \n",
    "            plt.plot(s_arr, marker='o')\n",
    "            plt.plot(e_arr, marker='o')\n",
    "            plt.title(\"Positional cues\")\n",
    "            plt.show()\n",
    "\n",
    "        return s_arr, e_arr, c_arr\n",
    "\n",
    "    def positional_overlap(self, n, plot=False):\n",
    "\n",
    "        for i in range(n):\n",
    "            pos_sim = []\n",
    "            for j in range(n):\n",
    "                s, e =self.start_end_markers(i+1)\n",
    "                s2, e2 = self.start_end_markers(j+1)\n",
    "                p1 = np.asarray((s,e))\n",
    "                p2 = np.asarray((s2, e2))\n",
    "                o = self.overlap_function(p1, p2)\n",
    "                pos_sim.append(o)\n",
    "            if plot:\n",
    "                plt.plot(pos_sim, marker='o')\n",
    "\n",
    "        if plot:\n",
    "            plt.title(\"Positional overlap\")\n",
    "            plt.show()\n",
    "\n",
    "        return pos_sim \n",
    "\n",
    "    def add_token(self, item, list_position, group_position, phono_activation, context, suppression):\n",
    "\n",
    "        '''\n",
    "        Add tokens and modify phonological + suppression type representations \n",
    "\n",
    "        :param int item: integer corresponding to item \n",
    "        :param list list_position: start and end values coding list position\n",
    "        :param list group_position: start and end values coding group position\n",
    "        :param float phono_activation: how much to boost phonological type representation \n",
    "        :param float context: context value of token \n",
    "        :param float suppression: response suppression value of type representation \n",
    "        '''\n",
    "        \n",
    "        # ensure stored tokens are all the same length \n",
    "        assert len(self.stored_tokens) == len(self.list_position_tokens) == \\\n",
    "        len(self.group_position_tokens) == len(self.context_tokens), \\\n",
    "        print(\"Token lengths are not matching.\")\n",
    "\n",
    "        # if at max limit, pop first token from all lists \n",
    "        if len(self.stored_tokens) == self.max_tokens:\n",
    "            self.stored_tokens.pop(0)\n",
    "            self.list_position_tokens.pop(0)\n",
    "            self.group_position_tokens.pop(0)\n",
    "            self.context_tokens.pop(0)\n",
    "\n",
    "        self.stored_tokens.append(item)\n",
    "        self.list_position_tokens.append(list_position)\n",
    "        self.group_position_tokens.append(group_position)\n",
    "        self.context_tokens.append(context)\n",
    "\n",
    "        # modify response suppression and phonological attributes of type representations\n",
    "        self.response_suppression[item] = suppression\n",
    "        self.phonological_activations[item] = phono_activation\n",
    "\n",
    "    def list_presentation(self, list_length, group_size, items):\n",
    "\n",
    "        '''\n",
    "        :param int list_length: \n",
    "        :param int group_size \n",
    "        :param list items: each element is an integer corresponding to a item(0 is A, 25 is Z)\n",
    "        '''\n",
    "\n",
    "        # before presenting new items\n",
    "        self.contextual_change_acrosstrials()\n",
    "        self.current_list = items \n",
    "\n",
    "        for lp, item in enumerate(items):\n",
    "            \n",
    "            # between presentation of each item incorporate C_p episodes of \n",
    "            # contextual + phonological + response suppression (rs) decay\n",
    "            if lp != 0:\n",
    "                for i in range(self.C_p):\n",
    "                    self.decay_context_phono()\n",
    "\n",
    "            # obtain start and end markers for list and group position \n",
    "            gp = lp % group_size\n",
    "            lp_marker, gp_marker = self.start_end_markers(list_length, group_size, lp+1, gp+1)\n",
    "            self.add_token(item, lp_marker, gp_marker, self.A_p, self.present_context, 1-self.suppression)\n",
    "\n",
    "            self.response_suppression *= np.exp(-self.R_s)\n",
    "\n",
    "        # model effects of retention interval\n",
    "        for i in range(self.C_d):\n",
    "            self.decay_context_phono()\n",
    "\n",
    "    def contextual_change_acrosstrials(self):\n",
    "        \n",
    "        # contextual decay for C_a + C_i episodes\n",
    "        for i in range(self.C_a+self.C_i):\n",
    "            self.context_tokens = [x*self.E_c for x in self.context_tokens]\n",
    "            # phonological decay for C_i episodes \n",
    "            if i > self.C_a:\n",
    "                self.phonological_activations *= np.exp(-self.R_p)\n",
    "\n",
    "    def decay_context_phono(self):\n",
    "\n",
    "        '''\n",
    "        Performs one timestep of decay on contextual + phonological informatiton \n",
    "        '''\n",
    "\n",
    "        self.context_tokens = [x*self.E_c for x in self.context_tokens]\n",
    "        self.phonological_activations *= np.exp(-self.R_p)\n",
    "\n",
    "\n",
    "    def recall_selection(self, recall_list_cue, recall_group_cue, grouping=False):\n",
    "\n",
    "        '''\n",
    "        Input: \n",
    "        :param int recall_list_cue: list position used to initiate recall \n",
    "        :param int recall_group_cue: group position used to initiate recall \n",
    "\n",
    "        Output: \n",
    "        item selected for retrieval, or if no item was selected an omission response. \n",
    "        '''\n",
    "\n",
    "        # init. all type strengths to 0 \n",
    "        # although SEM stores episodic tokens in STM, the response competition phase\n",
    "        # is performed over the type representations in LTM.\n",
    "\n",
    "        type_strengths = np.zeros(self.vocab_size)\n",
    "\n",
    "        # obtain start and end markers based on cue\n",
    "        rl_query, rg_query = self.start_end_markers(self.list_length, self.group_size, recall_list_cue, recall_group_cue)\n",
    "\n",
    "        # compute overlap between retreival position + contextual cues and stored tokens\n",
    "        # store the maximum overlap strength for each type representation \n",
    "        for i in range(len(self.list_position_tokens)):  \n",
    "\n",
    "            # record item \n",
    "            item = int(self.stored_tokens[i])\n",
    "\n",
    "            # skip if item is an omission response \n",
    "            if item == -1:\n",
    "                continue\n",
    "\n",
    "            # overlap between query list position (lp) and stored list position tokens \n",
    "            o_lp = self.overlap_function(rl_query, self.list_position_tokens[i])\n",
    "\n",
    "            if grouping:\n",
    "                o_gp = self.overlap_function(rg_query, self.group_position_tokens[i])\n",
    "            else:\n",
    "                o_gp = 1 # if no grouping, set group overlap strength to 1 \n",
    "\n",
    "            o_c = self.overlap_function(self.present_context, self.context_tokens[i]) # will bias retrieval towards most recent tokens \n",
    "\n",
    "            overlap_strength = o_lp*o_gp*o_c*(1-self.response_suppression[item]) \n",
    "            \n",
    "            # only store max overlap strength value for each item \n",
    "            if type_strengths[item] < overlap_strength:\n",
    "                type_strengths[item] = overlap_strength\n",
    "                \n",
    "        # add noise to type strengths \n",
    "        type_strengths += np.random.default_rng().normal(0, self.G_c, type_strengths.shape[0])\n",
    "\n",
    "        recalled_item = self.phonological_selection(type_strengths)\n",
    "\n",
    "        if recalled_item not in self.current_list:\n",
    "            self.num_intrusions += 1\n",
    "\n",
    "        # decay values after recalling an item \n",
    "        for i in range(self.C_r):\n",
    "            self.decay_context_phono()\n",
    "       \n",
    "        self.response_suppression *= np.exp(-self.R_s)\n",
    "\n",
    "        # recode recalled_item as a new token \n",
    "        # if omission response, record everything as -1 \n",
    "        if np.isnan(recalled_item):\n",
    "            self.add_token(-1, np.asarray([-1,-1]), np.asarray([-1,-1]), -1, -1, -1)\n",
    "        else:\n",
    "            self.add_token(int(recalled_item), rl_query, rg_query, self.A_p, self.present_context, self.suppression)\n",
    "\n",
    "    def phonological_sim(self, item1, item2):\n",
    "\n",
    "        if item1 == item2:\n",
    "            return 1\n",
    "            \n",
    "        # assume all items are non-confusable for now \n",
    "        else:\n",
    "            return self.P_d\n",
    "\n",
    "    def phonological_selection(self, type_strengths):\n",
    "\n",
    "        # strongest item from cueing stage \n",
    "        strongest_item = np.argmax(type_strengths)\n",
    "        type_strengths_phono = np.zeros(self.vocab_size)\n",
    "\n",
    "        # incorporate effects of phonological similarity\n",
    "        for item, ts in enumerate(type_strengths):\n",
    "\n",
    "            # provide a boost to items that are phonologically similar to the strongest activated item \n",
    "            phono_boost =  self.phonological_sim(item, strongest_item) * \\\n",
    "            self.phonological_activations[strongest_item]*(1-self.response_suppression[item])\n",
    "            type_strengths_phono[item] = ts + phono_boost + np.random.default_rng().normal(0, self.G_p, 1)[0]\n",
    "        \n",
    "        max_activation = np.max(type_strengths_phono)\n",
    "\n",
    "        if max_activation > self.T_o: \n",
    "            recalled_item = np.argmax(type_strengths_phono)\n",
    "        else:\n",
    "            recalled_item = np.nan\n",
    "            self.num_omissions += 1\n",
    "\n",
    "        return recalled_item\n",
    "\n",
    "    def simulate_trials(self, num_trials, list_length, group_size):\n",
    "\n",
    "        self.list_length = list_length\n",
    "        self.group_size = group_size\n",
    "\n",
    "        for trial in range(num_trials):\n",
    "\n",
    "            # sample list length items from vocab size \n",
    "            self.current_list= np.random.default_rng().choice(self.vocab_size, self.list_length, replace=False)\n",
    "            self.list_presentation(self.list_length, self.group_size, self.current_list)\n",
    "\n",
    "            # recall items\n",
    "            for i in range(1, self.list_length+1, 1):\n",
    "                self.recall_selection(i,i)\n",
    "\n",
    "            self.num_correct += self.compute_accuracy()\n",
    "\n",
    "            self.reshape_stored_tokens()\n",
    "\n",
    "    def compute_accuracy(self):\n",
    "\n",
    "        recalled_list = self.stored_tokens[-self.list_length:]\n",
    "\n",
    "        if list(self.current_list) == recalled_list:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def reshape_stored_tokens(self):\n",
    "\n",
    "        self.all_stored_tokens.append(self.stored_tokens[-self.list_length*2:])\n",
    "        tokens_np = np.array(self.all_stored_tokens).ravel()\n",
    "        tokens_np_reshape = np.reshape(tokens_np, (int(tokens_np.shape[0]/self.list_length), self.list_length))\n",
    "        self.presented_tokens = tokens_np_reshape[::2]\n",
    "        self.recalled_tokens = tokens_np_reshape[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPR: 0.22\n",
      "Num omissions: 13\n",
      "Num intrusions: 68\n",
      "PPR: 0.4\n",
      "Num omissions: 0\n",
      "Num intrusions: 37\n"
     ]
    }
   ],
   "source": [
    "demonstration_5_params = {'s0': 1.0, 'e0': 0.60, 'S':0.8 , 'E': 0.48, 'G_c': 0.08, 'G_p':0, 'R_s': 0.50, \n",
    "                        'R_p': 0.20, 'T_o': 0.35, 'E_c': 0.98, 'C_p': 1, 'C_d': 0, 'C_r': 1, 'C_i': 0, 'C_a': 5, 'A_p':0,\n",
    "                        'P_s':1, 'P_d':0, 'vocab_size': 12, 'max_tokens':30}\n",
    "\n",
    "\n",
    "demonstration_6_params = {'s0': 1.0, 'e0': 0.60, 'S':0.8 , 'E': 0.48, 'G_c':0.06, 'G_p':0.14, 'R_s': 0.50, \n",
    "                        'R_p': 0.20, 'T_o': 0.35, 'E_c': 0.98, 'C_p': 1, 'C_d': 0, 'C_r': 1, 'C_i': 0, 'C_a': 5, 'A_p':1,\n",
    "                        'P_s':1, 'P_d':0, 'vocab_size': 12, 'max_tokens':30}\n",
    "\n",
    "num_trials = 100\n",
    "list_length = 6\n",
    "group_length = 6\n",
    "mtSEM_5 = MultiTrialSEM(demonstration_5_params)\n",
    "mtSEM_5.simulate_trials(num_trials, list_length, group_length)\n",
    "print(f\"PPR: {mtSEM_5.num_correct / num_trials}\")\n",
    "print(f\"Num omissions: {mtSEM_5.num_omissions}\")\n",
    "print(f\"Num intrusions: {mtSEM_5.num_intrusions}\")\n",
    "\n",
    "num_trials = 100\n",
    "list_length = 6\n",
    "group_length = 6\n",
    "mtSEM_6 = MultiTrialSEM(demonstration_6_params)\n",
    "mtSEM_6.simulate_trials(num_trials, list_length, group_length)\n",
    "print(f\"PPR: {mtSEM_6.num_correct / num_trials}\")\n",
    "print(f\"Num omissions: {mtSEM_6.num_omissions}\")\n",
    "print(f\"Num intrusions: {mtSEM_6.num_intrusions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
